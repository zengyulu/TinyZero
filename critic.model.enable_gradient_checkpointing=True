2025-01-31 22:41:26,019	INFO worker.py:1832 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
[36m(main_task pid=102190)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=102190)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=102190)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=102190)[0m                                                  'grad_offload': False,
[36m(main_task pid=102190)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=102190)[0m                                                  'param_offload': False,
[36m(main_task pid=102190)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=102190)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=102190)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=102190)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=102190)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=102190)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=102190)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=102190)[0m                                            'total_training_steps': -1,
[36m(main_task pid=102190)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=102190)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=102190)[0m                                  'ppo_max_token_len_per_gpu': 16384,
[36m(main_task pid=102190)[0m                                  'ppo_micro_batch_size': 8,
[36m(main_task pid=102190)[0m                                  'ppo_mini_batch_size': 128,
[36m(main_task pid=102190)[0m                                  'shuffle': False,
[36m(main_task pid=102190)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=102190)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=102190)[0m                                  'use_dynamic_bsz': False,
[36m(main_task pid=102190)[0m                                  'use_kl_loss': False},
[36m(main_task pid=102190)[0m                        'hybrid_engine': True,
[36m(main_task pid=102190)[0m                        'model': {'enable_gradient_checkpointing': False,
[36m(main_task pid=102190)[0m                                  'external_lib': None,
[36m(main_task pid=102190)[0m                                  'override_config': {},
[36m(main_task pid=102190)[0m                                  'path': '/home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B',
[36m(main_task pid=102190)[0m                                  'use_remove_padding': False},
[36m(main_task pid=102190)[0m                        'ref': {'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=102190)[0m                                                'param_offload': False,
[36m(main_task pid=102190)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=102190)[0m                                'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=102190)[0m                                'log_prob_micro_batch_size': 4,
[36m(main_task pid=102190)[0m                                'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=102190)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=102190)[0m                        'rollout': {'do_sample': True,
[36m(main_task pid=102190)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=102190)[0m                                    'enforce_eager': True,
[36m(main_task pid=102190)[0m                                    'free_cache_engine': True,
[36m(main_task pid=102190)[0m                                    'gpu_memory_utilization': 0.4,
[36m(main_task pid=102190)[0m                                    'ignore_eos': False,
[36m(main_task pid=102190)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=102190)[0m                                    'log_prob_max_token_len_per_gpu': 16384,
[36m(main_task pid=102190)[0m                                    'log_prob_micro_batch_size': 8,
[36m(main_task pid=102190)[0m                                    'log_prob_use_dynamic_bsz': False,
[36m(main_task pid=102190)[0m                                    'max_num_batched_tokens': 8192,
[36m(main_task pid=102190)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=102190)[0m                                    'n': 1,
[36m(main_task pid=102190)[0m                                    'name': 'vllm',
[36m(main_task pid=102190)[0m                                    'prompt_length': 256,
[36m(main_task pid=102190)[0m                                    'response_length': 1024,
[36m(main_task pid=102190)[0m                                    'temperature': 1.0,
[36m(main_task pid=102190)[0m                                    'tensor_model_parallel_size': 2,
[36m(main_task pid=102190)[0m                                    'top_k': -1,
[36m(main_task pid=102190)[0m                                    'top_p': 1}},
[36m(main_task pid=102190)[0m  'algorithm': {'adv_estimator': 'gae',
[36m(main_task pid=102190)[0m                'gamma': 1.0,
[36m(main_task pid=102190)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=102190)[0m                'kl_penalty': 'kl',
[36m(main_task pid=102190)[0m                'lam': 1.0},
[36m(main_task pid=102190)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=102190)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=102190)[0m             'forward_micro_batch_size': 8,
[36m(main_task pid=102190)[0m             'grad_clip': 1.0,
[36m(main_task pid=102190)[0m             'model': {'enable_gradient_checkpointing': False,
[36m(main_task pid=102190)[0m                       'external_lib': None,
[36m(main_task pid=102190)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=102190)[0m                                       'grad_offload': False,
[36m(main_task pid=102190)[0m                                       'optimizer_offload': False,
[36m(main_task pid=102190)[0m                                       'param_offload': False,
[36m(main_task pid=102190)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=102190)[0m                       'override_config': {},
[36m(main_task pid=102190)[0m                       'path': '/home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B',
[36m(main_task pid=102190)[0m                       'tokenizer_path': '/home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B',
[36m(main_task pid=102190)[0m                       'use_remove_padding': False},
[36m(main_task pid=102190)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=102190)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=102190)[0m                       'min_lr_ratio': None,
[36m(main_task pid=102190)[0m                       'total_training_steps': -1,
[36m(main_task pid=102190)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=102190)[0m             'ppo_epochs': 1,
[36m(main_task pid=102190)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=102190)[0m             'ppo_micro_batch_size': 8,
[36m(main_task pid=102190)[0m             'ppo_mini_batch_size': 128,
[36m(main_task pid=102190)[0m             'shuffle': False,
[36m(main_task pid=102190)[0m             'strategy': 'fsdp',
[36m(main_task pid=102190)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=102190)[0m             'use_dynamic_bsz': False},
[36m(main_task pid=102190)[0m  'data': {'max_prompt_length': 256,
[36m(main_task pid=102190)[0m           'max_response_length': 1024,[36m(main_task pid=102190)[0m /home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(main_task pid=102190)[0m No module named 'vllm._version'
[36m(main_task pid=102190)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=102576)[0m /home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(pid=102576)[0m No module named 'vllm._version'[32m [repeated 2x across cluster][0m
[36m(pid=102576)[0m   from vllm.version import __version__ as VLLM_VERSION[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=102373)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=102373)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=102373)[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
[36m(WorkerDict pid=102576)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.21it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 14.19it/s]
[36m(WorkerDict pid=102576)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at /home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B and are newly initialized: ['score.bias']
[36m(WorkerDict pid=102576)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=102373)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.54s/it]
[36m(WorkerDict pid=102373)[0m Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at /home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B and are newly initialized: ['score.bias', 'score.weight']
[36m(WorkerDict pid=102576)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForTokenClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=102576)[0m You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[36m(WorkerDict pid=102373)[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=102373)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.22s/it]
[36m(WorkerDict pid=102373)[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[36m(WorkerDict pid=102373)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.71it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.70it/s]
[36m(WorkerDict pid=102373)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=102373)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.61s/it]

[36m(main_task pid=102190)[0m           'prompt_key': 'prompt',
[36m(main_task pid=102190)[0m           'return_raw_chat': False,
[36m(main_task pid=102190)[0m           'return_raw_input_ids': False,
[36m(main_task pid=102190)[0m           'tokenizer': None,
[36m(main_task pid=102190)[0m           'train_batch_size': 256,
[36m(main_task pid=102190)[0m           'train_files': '/home/zengyu/Workspace/0_git/TinyZero/data/train/train.parquet',
[36m(main_task pid=102190)[0m           'val_batch_size': 1312,
[36m(main_task pid=102190)[0m           'val_files': '/home/zengyu/Workspace/0_git/TinyZero/data/train/test.parquet'},
[36m(main_task pid=102190)[0m  'reward_model': {'enable': False,
[36m(main_task pid=102190)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=102190)[0m                   'max_length': None,
[36m(main_task pid=102190)[0m                   'micro_batch_size': 64,
[36m(main_task pid=102190)[0m                   'model': {'external_lib': None,
[36m(main_task pid=102190)[0m                             'fsdp_config': {'min_num_params': 0,
[36m(main_task pid=102190)[0m                                             'param_offload': False},
[36m(main_task pid=102190)[0m                             'input_tokenizer': '/home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B',
[36m(main_task pid=102190)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=102190)[0m                             'use_remove_padding': False},
[36m(main_task pid=102190)[0m                   'strategy': 'fsdp',
[36m(main_task pid=102190)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=102190)[0m                   'use_dynamic_bsz': False},
[36m(main_task pid=102190)[0m  'trainer': {'critic_warmup': 0,
[36m(main_task pid=102190)[0m              'default_hdfs_dir': None,
[36m(main_task pid=102190)[0m              'default_local_dir': 'checkpoints/TinyZero/countdown-qwen2.5-3b',
[36m(main_task pid=102190)[0m              'experiment_name': 'countdown-qwen2.5-3b',
[36m(main_task pid=102190)[0m              'logger': ['wandb'],
[36m(main_task pid=102190)[0m              'n_gpus_per_node': 2,
[36m(main_task pid=102190)[0m              'nnodes': 1,
[36m(main_task pid=102190)[0m              'project_name': 'TinyZero',
[36m(main_task pid=102190)[0m              'save_freq': 100,
[36m(main_task pid=102190)[0m              'test_freq': 100,
[36m(main_task pid=102190)[0m              'total_epochs': 15,
[36m(main_task pid=102190)[0m              'total_training_steps': None,
[36m(main_task pid=102190)[0m              'val_before_train': False}}
[36m(main_task pid=102190)[0m original dataset len: 327680
[36m(main_task pid=102190)[0m filter dataset len: 327680
[36m(main_task pid=102190)[0m original dataset len: 1024
[36m(main_task pid=102190)[0m filter dataset len: 1024
[36m(main_task pid=102190)[0m Size of train dataloader: 1280
[36m(main_task pid=102190)[0m Size of val dataloader: 1
[36m(main_task pid=102190)[0m Total training steps: 19200
[36m(WorkerDict pid=102373)[0m Critic overriding config {'bos_token_id': None, 'eos_token_id': 151643, 'pad_token_id': 151643}
[36m(WorkerDict pid=102373)[0m Qwen2ForTokenClassification contains 3.09B parameters
[36m(WorkerDict pid=102373)[0m Before critic FSDP, memory allocated (GB): 0.0, memory reserved (GB): 0.0
[36m(WorkerDict pid=102373)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=102373)[0m After critic FSDP, memory allocated (GB): 5.7832207679748535, memory reserved (GB): 10.130859375
[36m(WorkerDict pid=102373)[0m Total steps: 19200, num_warmup_steps: 0
[36m(WorkerDict pid=102373)[0m Critic use_remove_padding=False
[36m(WorkerDict pid=102373)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=102373)[0m   "_name_or_path": "/home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B",
[36m(WorkerDict pid=102373)[0m   "architectures": [
[36m(WorkerDict pid=102373)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=102373)[0m   ],
[36m(WorkerDict pid=102373)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=102373)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=102373)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=102373)[0m   "hidden_size": 2048,
[36m(WorkerDict pid=102373)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=102373)[0m   "intermediate_size": 11008,
[36m(WorkerDict pid=102373)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=102373)[0m   "max_window_layers": 36,
[36m(WorkerDict pid=102373)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=102373)[0m   "num_attention_heads": 16,
[36m(WorkerDict pid=102373)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=102373)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=102373)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=102373)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=102373)[0m   "rope_scaling": null,
[36m(WorkerDict pid=102373)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=102373)[0m   "sliding_window": null,
[36m(WorkerDict pid=102373)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=102373)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=102373)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=102373)[0m   "use_cache": true,
[36m(WorkerDict pid=102373)[0m   "use_mrope": false,
[36m(WorkerDict pid=102373)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=102373)[0m   "vocab_size": 151936
[36m(WorkerDict pid=102373)[0m }
[36m(WorkerDict pid=102373)[0m 
[36m(WorkerDict pid=102373)[0m Qwen2ForCausalLM contains 3.09B parameters
[36m(WorkerDict pid=102373)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x76d8d9d2b240>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(WorkerDict pid=102373)[0m Actor use_remove_padding=False
[36m(WorkerDict pid=102373)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=102373)[0m   "_name_or_path": "/home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B",
[36m(WorkerDict pid=102373)[0m   "architectures": [
[36m(WorkerDict pid=102373)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=102373)[0m   ],
[36m(WorkerDict pid=102373)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=102373)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=102373)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=102373)[0m   "hidden_size": 2048,
[36m(WorkerDict pid=102373)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=102373)[0m   "intermediate_size": 11008,
[36m(WorkerDict pid=102373)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=102373)[0m   "max_window_layers": 36,
[36m(WorkerDict pid=102373)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=102373)[0m   "num_attention_heads": 16,
[36m(WorkerDict pid=102373)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=102373)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=102373)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=102373)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=102373)[0m   "rope_scaling": null,
[36m(WorkerDict pid=102373)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=102373)[0m   "sliding_window": null,
[36m(WorkerDict pid=102373)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=102373)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=102373)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=102373)[0m   "use_cache": true,
[36m(WorkerDict pid=102373)[0m   "use_mrope": false,
[36m(WorkerDict pid=102373)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=102373)[0m   "vocab_size": 151936
[36m(WorkerDict pid=102373)[0m }
[36m(WorkerDict pid=102373)[0m 
[36m(WorkerDict pid=102373)[0m Qwen2ForCausalLM contains 3.09B parameters
[36m(WorkerDict pid=102373)[0m Before building vllm rollout, memory allocated (GB): 14.457818984985352, memory reserved (GB): 18.806640625
[36m(WorkerDict pid=102373)[0m Total steps: 19200, num_warmup_steps: 0[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=102576)[0m Critic use_remove_padding=False[36m(WorkerDict pid=102373)[0m /home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
[36m(WorkerDict pid=102373)[0m   @torch.library.impl_abstract("xformers_flash::flash_fwd")
[36m(WorkerDict pid=102373)[0m /home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
[36m(WorkerDict pid=102373)[0m   @torch.library.impl_abstract("xformers_flash::flash_bwd")
[36m(WorkerDict pid=102576)[0m Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102576)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.22s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.28s/it][32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102576)[0m Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in Qwen2ForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained("openai/whisper-tiny", attn_implementation="flash_attention_2", torch_dtype=torch.float16)`
[36m(WorkerDict pid=102576)[0m Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.62s/it]
[36m(WorkerDict pid=102373)[0m /home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=102373)[0m   warnings.warn(
[36m(main_task pid=102190)[0m wandb: Currently logged in as: zengyu_lu (finmark) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[36m(main_task pid=102190)[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[36m(main_task pid=102190)[0m wandb: Tracking run with wandb version 0.19.5
[36m(main_task pid=102190)[0m wandb: Run data is saved locally in /home/zengyu/Workspace/0_git/TinyZero/wandb/run-20250131_224150-2c0urjr3
[36m(main_task pid=102190)[0m wandb: Run `wandb offline` to turn off syncing.
[36m(main_task pid=102190)[0m wandb: Syncing run countdown-qwen2.5-3b
[36m(main_task pid=102190)[0m wandb: â­ï¸ View project at https://wandb.ai/finmark/TinyZero
[36m(main_task pid=102190)[0m wandb: ðŸš€ View run at https://wandb.ai/finmark/TinyZero/runs/2c0urjr3

[36m(WorkerDict pid=102576)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x792acc14b240>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102373)[0m Actor use_remove_padding=False[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=102373)[0m INFO 01-31 22:41:47 config.py:887] Defaulting to use ray for distributed inference
[36m(WorkerDict pid=102373)[0m WARNING 01-31 22:41:47 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=102373)[0m local rank 0
[36m(WorkerDict pid=102373)[0m INFO 01-31 22:41:47 selector.py:115] Using XFormers backend.
[36m(WorkerDict pid=102373)[0m INFO 01-31 22:41:47 utils.py:1008] Found nccl from library libnccl.so.2
[36m(WorkerDict pid=102373)[0m INFO 01-31 22:41:47 pynccl.py:63] vLLM is using nccl==2.20.5
[36m(WorkerDict pid=102373)[0m INFO 01-31 22:41:47 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x76d86e118b90>, local_subscribe_port=57241, remote_subscribe_port=None)
[36m(WorkerDict pid=102373)[0m before init cache memory allocated: 18.683588096GB, reserved: 18.746441728GB
[36m(WorkerDict pid=102373)[0m after init cache memory allocated: 20.495527424GB, reserved: 20.558381056GB
[36m(WorkerDict pid=102373)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
[36m(WorkerDict pid=102373)[0m After building vllm rollout, memory allocated (GB): 16.16106939315796, memory reserved (GB): 19.146484375
[36m(WorkerDict pid=102373)[0m After building sharding manager, memory allocated (GB): 16.16106939315796, memory reserved (GB): 19.146484375
[36m(main_task pid=102190)[0m epoch 0, step 1
[36m(WorkerDict pid=102576)[0m Total steps: 19200, num_warmup_steps: 0
[36m(WorkerDict pid=102576)[0m Actor use_remove_padding=False
Error executing job with overrides: ['data.train_files=/home/zengyu/Workspace/0_git/TinyZero/data/train/train.parquet', 'data.val_files=/home/zengyu/Workspace/0_git/TinyZero/data/train/test.parquet', 'data.train_batch_size=256', 'data.val_batch_size=1312', 'data.max_prompt_length=256', 'data.max_response_length=1024', 'actor_rollout_ref.model.path=/home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.ppo_mini_batch_size=128', 'actor_rollout_ref.actor.ppo_micro_batch_size=8', 'actor_rollout_ref.rollout.log_prob_micro_batch_size=8', 'actor_rollout_ref.rollout.tensor_model_parallel_size=2', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.4', 'actor_rollout_ref.ref.log_prob_micro_batch_size=4', 'critic.optim.lr=1e-5', 'critic.model.path=/home/zengyu/Workspace/2_models/Qwen2/Qwen2.5-3B', 'critic.ppo_micro_batch_size=8', 'algorithm.kl_ctrl.kl_coef=0.001', 'trainer.logger=[wandb]', '+trainer.val_before_train=False', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=2', 'trainer.nnodes=1', 'trainer.save_freq=100', 'trainer.test_freq=100', 'trainer.project_name=TinyZero', 'trainer.experiment_name=countdown-qwen2.5-3b', 'trainer.total_epochs=15']
[36m(main_task pid=102190)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=102373, ip=192.168.178.104, actor_id=a827237fb99bdc20a3cebfd701000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x76d8a99767d0>)
[36m(main_task pid=102190)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/Workspace/0_git/TinyZero/verl/single_controller/ray/base.py", line 399, in func
[36m(main_task pid=102190)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(main_task pid=102190)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/Workspace/0_git/TinyZero/verl/single_controller/base/decorator.py", line 404, in inner
[36m(main_task pid=102190)[0m     return func(*args, **kwargs)
[36m(main_task pid=102190)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/Workspace/0_git/TinyZero/verl/workers/fsdp_workers.py", line 415, in generate_sequences
[36m(main_task pid=102190)[0m     with self.rollout_sharding_manager:
[36m(main_task pid=102190)[0m   File "/home/zengyu/Workspace/0_git/TinyZero/verl/workers/sharding_manager/fsdp_vllm.py", line 71, in __enter__
[36m(main_task pid=102190)[0m     params = self.module.state_dict()
[36m(main_task pid=102190)[0m              ^^^^^^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1941, in state_dict
[36m(main_task pid=102190)[0m     hook_result = hook(self, destination, prefix, local_metadata)
[36m(main_task pid=102190)[0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[36m(main_task pid=102190)[0m     return func(*args, **kwargs)
[36m(main_task pid=102190)[0m            ^^^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py", line 729, in _post_state_dict_hook
[36m(main_task pid=102190)[0m     processed_state_dict = _post_state_dict_hook_fn[fsdp_state._state_dict_type](
[36m(main_task pid=102190)[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py", line 574, in _sharded_post_state_dict_hook
[36m(main_task pid=102190)[0m     return _common_unshard_post_state_dict_hook(
[36m(main_task pid=102190)[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py", line 243, in _common_unshard_post_state_dict_hook
[36m(main_task pid=102190)[0m     param_hook(state_dict, prefix, fqn)
[36m(main_task pid=102190)[0m   File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py", line 564, in param_hook
[36m(main_task pid=102190)[0m     sharded_tensor = _ext_chunk_dtensor(
[36m(main_task pid=102190)[0m                      ^^^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_fsdp_extensions.py", line 150, in _ext_chunk_dtensor
[36m(main_task pid=102190)[0m     return chunk_dtensor_fn(
[36m(main_task pid=102190)[0m            ^^^^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m   File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_shard_utils.py", line 99, in _create_chunk_dtensor
[36m(main_task pid=102190)[0m     tensor = tensor.clone().detach()
[36m(main_task pid=102190)[0m              ^^^^^^^^^^^^^^
[36m(main_task pid=102190)[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 23.68 GiB of which 571.62 MiB is free. Including non-PyTorch memory, this process has 23.08 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 85.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home/zengyu/Workspace/0_git/TinyZero/verl/trainer/main_ppo.py", line 103, in main
    ray.get(main_task.remote(config))
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/ray/_private/worker.py", line 2772, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::main_task()[39m (pid=102190, ip=192.168.178.104)
  File "/home/zengyu/Workspace/0_git/TinyZero/verl/trainer/main_ppo.py", line 189, in main_task
    trainer.fit()
  File "/home/zengyu/Workspace/0_git/TinyZero/verl/trainer/ppo/ray_trainer.py", line 589, in fit
    gen_batch_output = self.actor_rollout_wg.generate_sequences(gen_batch)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/Workspace/0_git/TinyZero/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(OutOfMemoryError): [36mray::WorkerDict.actor_rollout_generate_sequences()[39m (pid=102576, ip=192.168.178.104, actor_id=0aaed9759d86faba51f625a701000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x792a9c095950>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/Workspace/0_git/TinyZero/verl/single_controller/ray/base.py", line 399, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/Workspace/0_git/TinyZero/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/Workspace/0_git/TinyZero/verl/workers/fsdp_workers.py", line 415, in generate_sequences
    with self.rollout_sharding_manager:
  File "/home/zengyu/Workspace/0_git/TinyZero/verl/workers/sharding_manager/fsdp_vllm.py", line 71, in __enter__
    params = self.module.state_dict()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1941, in state_dict
    hook_result = hook(self, destination, prefix, local_metadata)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py", line 729, in _post_state_dict_hook
    processed_state_dict = _post_state_dict_hook_fn[fsdp_state._state_dict_type](
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py", line 574, in _sharded_post_state_dict_hook
    return _common_unshard_post_state_dict_hook(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py", line 243, in _common_unshard_post_state_dict_hook
    param_hook(state_dict, prefix, fqn)
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_state_dict_utils.py", line 564, in param_hook
    sharded_tensor = _ext_chunk_dtensor(
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_fsdp_extensions.py", line 150, in _ext_chunk_dtensor
    return chunk_dtensor_fn(
           ^^^^^^^^^^^^^^^^^
  File "/home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/_shard_utils.py", line 99, in _create_chunk_dtensor
    tensor = tensor.clone().detach()
             ^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacity of 23.68 GiB of which 585.12 MiB is free. Including non-PyTorch memory, this process has 23.08 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 85.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(WorkerDict pid=102576)[0m /home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.[32m [repeated 2x across cluster][0m
[36m(WorkerDict pid=102576)[0m   @torch.library.impl_abstract("xformers_flash::flash_fwd")
[36m(WorkerDict pid=102576)[0m   @torch.library.impl_abstract("xformers_flash::flash_bwd")
[36m(WorkerDict pid=102576)[0m /home/zengyu/anaconda3/envs/tinyzero/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:689: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
[36m(WorkerDict pid=102576)[0m   warnings.warn(
[36m(WorkerDict pid=102576)[0m INFO 01-31 22:41:47 config.py:887] Defaulting to use ray for distributed inference
[36m(WorkerDict pid=102576)[0m WARNING 01-31 22:41:47 config.py:380] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
[36m(WorkerDict pid=102576)[0m local rank 0
[36m(WorkerDict pid=102576)[0m INFO 01-31 22:41:47 selector.py:115] Using XFormers backend.[32m [repeated 3x across cluster][0m
[36m(WorkerDict pid=102576)[0m INFO 01-31 22:41:47 utils.py:1008] Found nccl from library libnccl.so.2
[36m(WorkerDict pid=102576)[0m INFO 01-31 22:41:47 pynccl.py:63] vLLM is using nccl==2.20.5
[36m(WorkerDict pid=102576)[0m kwargs: {'n': 1, 'logprobs': 1, 'max_tokens': 1024, 'detokenize': False, 'temperature': 1.0, 'top_k': -1, 'top_p': 1, 'ignore_eos': False}
